# Install required packages first if not installed
# pip install torch transformers

from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import json

# Device setup (CPU/GPU/MPS)
device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")

# Load LiquidAI LFM2-350M model and tokenizer
model_name = "LiquidAI/LFM2-350M"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name).to(device)

# --------------------------
# Smart Home Functions
# --------------------------
def turn_on_light(room: str):
    return {"status": f"Light in {room} turned ON"}

def turn_off_light(room: str):
    return {"status": f"Light in {room} turned OFF"}

def set_thermostat(temp: int):
    return {"status": f"Thermostat set to {temp}Â°C"}

def lock_door(door: str):
    return {"status": f"{door} door locked"}

def unlock_door(door: str):
    return {"status": f"{door} door unlocked"}

# Map function names to actual implementations
TOOLS = {
    "turn_on_light": turn_on_light,
    "turn_off_light": turn_off_light,
    "set_thermostat": set_thermostat,
    "lock_door": lock_door,
    "unlock_door": unlock_door
}

# --------------------------
# Define tools JSON for LFM2
# --------------------------
tools_json = [
    {
        "name": "turn_on_light",
        "description": "Turn on the light in a specified room",
        "parameters": {
            "type": "object",
            "properties": {
                "room": {"type": "string", "description": "Name of the room"}
            },
            "required": ["room"]
        }
    },
    {
        "name": "turn_off_light",
        "description": "Turn off the light in a specified room",
        "parameters": {
            "type": "object",
            "properties": {
                "room": {"type": "string", "description": "Name of the room"}
            },
            "required": ["room"]
        }
    },
    {
        "name": "set_thermostat",
        "description": "Set the home thermostat to a given temperature",
        "parameters": {
            "type": "object",
            "properties": {
                "temp": {"type": "integer", "description": "Target temperature in Celsius"}
            },
            "required": ["temp"]
        }
    },
    {
        "name": "lock_door",
        "description": "Lock a specified door",
        "parameters": {
            "type": "object",
            "properties": {
                "door": {"type": "string", "description": "Door name"}
            },
            "required": ["door"]
        }
    },
    {
        "name": "unlock_door",
        "description": "Unlock a specified door",
        "parameters": {
            "type": "object",
            "properties": {
                "door": {"type": "string", "description": "Door name"}
            },
            "required": ["door"]
        }
    }
]

# --------------------------
# Smart Home Assistant Loop
# --------------------------
def run_smart_home():
    print("Welcome to Smart Home Assistant! Type 'exit' to quit.\n")
    while True:
        user_input = input("User: ")
        if user_input.lower() == "exit":
            break

        # Construct prompt for LFM2 with tool definitions
        prompt = (
            "<|startoftext|><|im_start|>system\n"
            f"List of tools: <|tool_list_start|>{json.dumps(tools_json)}<|tool_list_end|><|im_end|>\n"
            f"<|im_start|>user\n{user_input}<|im_end|>\n<|im_start|>assistant\n"
        )

        inputs = tokenizer(prompt, return_tensors="pt").to(device)
        outputs = model.generate(**inputs, max_new_tokens=200)
        decoded = tokenizer.decode(outputs[0])

        # Extract function call if present
        if "<|tool_call_start|>" in decoded:
            start = decoded.index("<|tool_call_start|>") + len("<|tool_call_start|>")
            end = decoded.index("<|tool_call_end|>")
            func_call_str = decoded[start:end].strip()

            # Remove surrounding brackets if they exist
            if func_call_str.startswith("[") and func_call_str.endswith("]"):
                func_call_str = func_call_str[1:-1].strip()

            print(f"\n[Function call generated by LFM2]: {func_call_str}")

            try:
                # Parse function name and arguments
                func_name = func_call_str.split("(")[0]
                args_str = func_call_str.split("(")[1].rstrip(")")
                args_dict = {}
                if args_str:
                    for pair in args_str.split(","):
                        k, v = pair.split("=")
                        args_dict[k.strip()] = v.strip().strip('"')

                # Execute function
                result = TOOLS[func_name](**args_dict)
                print(f"[Smart Home System Response]: {result['status']}\n")

            except Exception as e:
                print(f"[Error executing function]: {e}\n")
        else:
            print(f"[Assistant]: {decoded}\n")

if __name__ == "__main__":
    run_smart_home()
